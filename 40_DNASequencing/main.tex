DNA (deoxyribonucleic acid) is the molecule that stores genetic information in all living organisms. It consists of two complementary strands twisted into a double helix, where each strand is a linear sequence of four chemical bases: adenine (\textcolor{green!60!black}{A}), cytosine (\textcolor{blue}{C}), guanine (\textcolor{orange}{G}), and thymine (\textcolor{red}{T}). The sequence of these bases encodes the instructions for building and maintaining an organism.

The central dogma of biology describes how genetic information flows: DNA is transcribed into RNA, which is translated into proteins. Each three-base sequence (codon) in DNA specifies one amino acid in the resulting protein. A single change in the DNA sequence can alter the protein's structure and function, causing disease or evolutionary adaptation. Understanding DNA sequences is a key component in understanding the molecular basis of life.

Consider a short DNA sequence: \textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{orange}{G}\textcolor{blue}{C}\textcolor{orange}{G}\textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{blue}{C}\textcolor{orange}{G}\textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{blue}{C}\textcolor{orange}{G}. This 12-base fragment contains four codons: \textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{orange}{G}, \textcolor{blue}{C}\textcolor{orange}{G}\textcolor{green!60!black}{A}, \textcolor{red}{T}\textcolor{blue}{C}\textcolor{orange}{G}, \textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{blue}{C}. The codon \textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{orange}{G} typically signals "start translation," while the others specify specific amino acids. If the first base changes from \textcolor{green!60!black}{A} to \textcolor{red}{T}, creating \textcolor{red}{T}\textcolor{red}{T}\textcolor{orange}{G}\textcolor{blue}{C}\textcolor{orange}{G}\textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{blue}{C}\textcolor{orange}{G}\textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{blue}{C}\textcolor{orange}{G}, the first codon becomes \textcolor{red}{T}\textcolor{red}{T}\textcolor{orange}{G}, which codes for a different amino acid, potentially altering the resulting protein's function.

DNA sequencing is the process of determining the exact order of bases in a DNA molecule. This requires overcoming a scale mismatch: individual bases measure roughly one nanometer, while human chromosomes stretch millions of bases long which makes it practically impossible to read the entire sequence in one pass.

The solution involves fragmenting DNA into manageable pieces, reading each fragment separately, then computationally reconstructing the original sequence. This creates two challenges. The first is the biochemical problem of reading individual fragments and the second is the algorithmic problem of assembling them correctly. Each generation of sequencing technology has approached these challenges in different ways.

Frederick Sanger solved the reading problem through controlled interruption of DNA synthesis. DNA polymerase builds new strands by adding nucleotides complementary to a template; a 3'-hydroxyl group on each nucleotide enables the next to attach. Sanger introduced dideoxynucleotides (ddNTPs) that lack this hydroxyl group, terminating synthesis when incorporated.

This process is probabilistic. In a mix containing a DNA template, primers, polymerase, all four normal dNTPs, and a small amount of one ddNTP type (e.g., dd\textcolor{green!60!black}{A}TP), the polymerase occasionally incorporates a dd\textcolor{green!60!black}{A}TP, terminating the strand. Across millions of template copies, this generates a collection of fragments of different lengths, each ending at a different \textcolor{green!60!black}{A} position.

Running four parallel reactions — one for each ddNTP type — produces four fragment collections. Gel electrophoresis separates these by size: DNA fragments migrate through a polymer matrix under an electric field, with smaller fragments moving faster. After separation, each gel lane shows a ladder of bands. Reading from shortest to longest fragment across all four lanes reveals the sequence. If the shortest fragment appears in the \textcolor{orange}{G} lane, the first base is \textcolor{orange}{G}. If the next shortest is in the \textcolor{green!60!black}{A} lane, the second base is \textcolor{green!60!black}{A}. Going through all four lanes reveals the sequence.

Sanger sequencing powered the Human Genome Project but had limitations. Each reaction produced only 500-1000 readable bases. Preparing samples, running gels, and reading results consumed hours per reaction. Radioactive or fluorescent labeling added complexity and cost. The throughput ceiling meant that sequencing a human genome required years of work and hundreds of millions of dollars.

Next-generation platforms achieved a breakthrough with parallelization, performing millions of reactions simultaneously on a single surface. Early systems distributed single DNA fragments into millions of microscopic wells and flowed one nucleotide type at a time (first all \textcolor{green!60!black}{A}s, wash; then all \textcolor{blue}{C}s, wash). Detection chemistry varied. 454 Life Sciences used pyrosequencing: nucleotide incorporation releases pyrophosphate (PPi), which an enzyme cascade converts into a light signal via luciferase. Ion Torrent used semiconductor sequencing: incorporation releases a hydrogen ion, and millions of ISFET (ion-sensitive field-effect transistor) sensors detect the resulting pH change as a voltage signal. Both methods suffered from the same core limitation. Because nucleotides were added sequentially, homopolymer runs like \textcolor{green!60!black}{A}\textcolor{green!60!black}{A}\textcolor{green!60!black}{A}\textcolor{green!60!black}{A} caused all four bases to incorporate at once, producing a signal four times stronger. Distinguishing a 4× signal from a 5× signal was error-prone, limiting accuracy.

Illumina took a different path, solving the homopolymer problem through reversible termination. Their innovation combined three key elements: surface-bound amplification, chemically cleavable terminators, and four-color imaging.

The process begins with bridge amplification. DNA fragments attach to a glass surface coated with two types of oligonucleotide primers. Each fragment bends to hybridize with a nearby complementary primer, forming a bridge. Polymerase extends the primer, creating a complementary strand anchored at both ends. Denaturation releases the original strand, and the process repeats. After 35 cycles, each original molecule generates a tight cluster of ~1000 identical copies, all within a few hundred nanometers — small enough to act as a single sequencing unit but bright enough for fluorescence detection.

Illumina's sequencing chemistry uses nucleotides engineered with two modifications: a fluorescent dye unique to each base (\textcolor{green!60!black}{A}, \textcolor{blue}{C}, \textcolor{orange}{G}, \textcolor{red}{T}) and a chemical block on the 3'-OH that prevents further extension. Unlike Sanger's permanent terminators, these blocks can be cleaved chemically.

Each sequencing cycle follows four steps: add all four labeled terminators simultaneously, wait for incorporation, image in four colors, then cleave both dye and terminator. Because only one base can be added per cycle (due to the 3'-block), homopolymers read accurately — \textcolor{green!60!black}{A}\textcolor{green!60!black}{A}\textcolor{green!60!black}{A}\textcolor{green!60!black}{A} requires four separate cycles, each adding one \textcolor{green!60!black}{A}. This solved 454's limitation.

Illumina's paired-end innovation provided long-range information. Sequence both ends of a DNA fragment, keeping track that they came from the same molecule. If fragments are 500 bases long but you only read 150 bases from each end, you know those two 150-base sequences sit 200 bases apart in the genome. These distance constraints prove essential for genome assembly.

Assembling a 3-billion-base human genome from 20 million 150-base fragments is computationally demanding. Early overlap-layout-consensus algorithms, which compare all read pairs to find overlaps, were feasible for thousands of Sanger reads but fail for millions of short reads where all-pairs comparison is prohibitive.

De Bruijn graphs, a 1946 mathematical structure, provided a scalable solution. Instead of connecting reads, they connect k-mers — all possible k-letter substrings. A sequence traces a path through a graph where each unique k-mer is a node and edges connect k-mers overlapping by k-1 bases. The scalability arises because a genome of length G contains at most $G-k+1$ distinct k-mers, regardless of sequencing depth. Finding Eulerian paths that traverse each edge once is tractable even for graphs with billions of nodes.

Consider the sequence \textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{blue}{C}\textcolor{orange}{G}\textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{blue}{C}\textcolor{orange}{G} and extract all 3-mers: \textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{blue}{C}, \textcolor{red}{T}\textcolor{blue}{C}\textcolor{orange}{G}, \textcolor{blue}{C}\textcolor{orange}{G}\textcolor{green!60!black}{A}, \textcolor{orange}{G}\textcolor{green!60!black}{A}\textcolor{red}{T}, \textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{blue}{C}, \textcolor{red}{T}\textcolor{blue}{C}\textcolor{orange}{G}. Build a graph where each unique k-mer is a node, and edges connect k-mers that overlap by k-1 bases. The sequence \textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{blue}{C}\textcolor{orange}{G}\textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{blue}{C}\textcolor{orange}{G} traces a path through this graph: \textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{blue}{C}→\textcolor{red}{T}\textcolor{blue}{C}\textcolor{orange}{G}→\textcolor{blue}{C}\textcolor{orange}{G}\textcolor{green!60!black}{A}→\textcolor{orange}{G}\textcolor{green!60!black}{A}\textcolor{red}{T}→\textcolor{green!60!black}{A}\textcolor{red}{T}\textcolor{blue}{C}→\textcolor{red}{T}\textcolor{blue}{C}\textcolor{orange}{G} (compare to the superpermutation problem in another chapter).

Repeats in the genome, such as transposable elements, complicate assembly. When a repeat is longer than a read, it creates ambiguity in the assembly graph, resulting in multiple valid paths. Paired-end constraints resolve some ambiguities, but short reads cannot span long repeats, requiring the development of long-read technologies.

Pacific Biosciences (PacBio) developed single-molecule real-time (SMRT) sequencing, observing individual DNA polymerase enzymes. The primary challenge was detecting single fluorescent nucleotides against the background of unincorporated ones. The solution was zero-mode waveguides (ZMWs): 70-nanometer holes in an aluminum film that confine laser illumination to a 20-zeptoliter volume. A polymerase at the bottom of each ZMW holds an incorporating nucleotide for milliseconds, long enough to generate a detectable fluorescent flash distinct from the transient signals of freely diffusing nucleotides. This method generates reads exceeding 10,000 bases. Though noisy, with error rates of 10-15\%, these long reads are effective at spanning genomic repeats.

Oxford Nanopore technology uses no enzymes or fluorescence. It passes a single DNA strand through a protein nanopore embedded in a membrane. An applied voltage drives both the DNA and an ionic current. As the DNA translocates, nucleotides in the pore's 1.4-nanometer constriction modulate the current. The narrowest region spans approximately five bases, so the signal reflects a 5-mer. Signal processing algorithms, and recently, neural networks, decode the complex current modulations into a DNA sequence, achieving >95\% accuracy and read lengths that can exceed one million bases.

Long reads simplified assembly graphs, as most repeats become trivial to span. Modern projects often use a hybrid approach: Illumina provides an accurate short-read backbone, while PacBio or Nanopore provides a long-read scaffold to resolve repeats and structural variants.

\newpage

\begin{commentary}[On Assembly Statistics]
Evaluating a genome assembly requires understanding its output format. Assemblies consist of fragments at two organizational levels. A \textbf{contig} is a contiguous stretch of sequence assembled from overlapping reads — an unbroken text. A \textbf{scaffold} links multiple contigs that are ordered and oriented but separated by gaps of estimated size. Consider recovering a book's text from shredded copies: contigs are complete pages reconstructed from overlapping fragments, scaffolds are chapters where page order is known but some pages remain missing.

Assembly statistics quantify output quality. The median contig length — the middle value in a sorted list — is uninformative because assemblies contain thousands of short contigs and few long ones. An assembly with 10,000 contigs might have a median length of 500 bases while its longest contigs exceed one million bases.

The \textbf{N50} statistic measures contiguity differently. Sort contigs from longest to shortest, then sum their lengths sequentially. The N50 is the length of the contig that brings this cumulative sum to 50\% of the total assembly size. It identifies the minimum length such that half the genome resides in contigs of that length or longer. For contigs of lengths 10, 9, 8, 7, 1, 1, 1, 1, and 1 kb (total 39 kb), the cumulative sum surpasses 50\% after adding the first three contigs ($10+9+8=27>39/2=19.5$ kb). The N50 is 8 kb — the length of that third contig. The median is 1 kb.

The scientific literature frequently misreports N50 as "median contig length (N50)." The N50 is a length-weighted metric, not the simple median of contig lengths. Describing N50 as a "weighted median" is correct if one creates an expanded list where each contig appears once for each base it contains, then takes that list's median.

This type of error is common when multidisciplinary knowledge is needed across distant fields such as biology and information science.
\end{commentary}

