Every program — from your web browser to your text editor — is a sequence of simple instructions that tell the processor what to do: load data from memory, store results back, add numbers, compare values. Think of it like a recipe where each step must be precise: "take flour from cabinet," "add to bowl," "mix ingredients." These instructions manipulate data stored in memory, the computer's workspace.

Memory is like a vast warehouse with different storage areas. Closest to the processor are registers — think of them as the processor's hands, holding just a few items it's actively working with. Next come caches, like workbenches near the assembly line, storing frequently-used data. Main memory is the large warehouse floor, holding gigabytes of data but taking longer to access. When you open a document, it moves from your hard drive into main memory, then pieces flow through caches to registers as the processor works on them.

Processors execute instructions through pipelines — assembly lines where different stages happen simultaneously. While one instruction is being decoded (figuring out what "add" means), another is being executed (actually adding numbers), and a third is being fetched from memory. This parallelism makes processors fast, executing billions of instructions per second. Dependencies constrain this parallelism. Adding $A+B$ requires knowing both values first. Processors analyze these dependencies and reorder independent operations to keep the pipeline flowing. 

The instruction \texttt{if (x < y)} determines whether certain code will be executed, but evaluating the condition takes time. Waiting would leave execution units idle. Instead, processors predict the outcome and speculatively execute that path. Branch predictors track patterns — loops usually continue, error checks usually pass, sorted data produces predictable comparisons.

If the prediction is correct, the speculative work becomes part of normal execution. If incorrect, the speculative instructions are discarded and execution switches to the correct path. From the perspective of the committed values of memory and registers, it is as if the speculation never occurred. Internally, though, speculative execution modifies shared state: caches (fast memory that stores recently accessed data), branch predictors, translation buffers, and other timing-sensitive components. As we will see, these modifications leave traces.

Modern computers set strict boundaries between different programs and between user programs and the operating system kernel. The kernel — the core of the operating system — manages hardware, controls security, and stores sensitive data like passwords, encryption keys, and private information from all running programs. User programs (your browser, text editor, games) are forbidden from reading kernel memory. Similarly, one user's programs cannot read another user's data. These restrictions are enforced through memory protection mechanisms built into the processor.

But what if these protections could be bypassed? Imagine requesting a book from a library where some rooms are restricted. To save time, the librarian starts walking toward the room before confirming whether you have access. If you are authorized, the book is delivered. If not, the librarian returns — nothing was given. But the door was opened. Now suppose you are not told which room contains which book. Later, you notice that one door swings more easily. You did not receive the book, but you know where the librarian went. This is a side channel attack — extracting secrets through indirect observations rather than direct access.

Meltdown (2018) is an example of an exploit that targets privileged kernel memory — the protected area containing the operating system's secrets. User programs attempting to read kernel memory trigger an immediate error, like trying to enter a secured building without a keycard. But during speculative execution, the processor starts fetching the forbidden data before checking permissions. The security check eventually catches this and triggers an exception — Meltdown never "officially" reads the secret. But in the microseconds between the speculative read and the security check, the secret value exists in the processor. The attack uses this value to access a specific location in the attacker's own memory array. When the security exception fires and speculation is cancelled, the secret itself is erased — but the access pattern remains in the cache. By timing how fast different array locations load, the attacker deduces which location was accessed, revealing the secret byte value.

Many operating systems historically mapped kernel pages into every user address space for performance. Meltdown exploited deferred permission checks on affected Intel CPUs, allowing transient use of privileged data before the fault was architecturally raised. AMD reported its CPUs were not affected by Meltdown; ARM susceptibility varied by core implementation.

Spectre trains the branch predictor, then exploits its predictions. During training, call a victim function repeatedly with valid array indices. The predictor learns that bounds checks like \texttt{if (x < array\_len)} succeed. During attack, provide an out-of-bounds index. Expecting success, the hardware speculatively reads \texttt{array[x]} beyond the array boundary. The speculative path uses this secret value as an index: \texttt{probe[secret * 4096]}. Each possible byte value maps to a different memory page, separated by 4KB to avoid cache-line collisions. After the misprediction triggers rollback, the attacker times accesses to all 256 probe pages. The fastest access reveals which page was cached, exposing the byte. Repeat to extract regions.

Branch predictors maintain 95\%+ accuracy by detecting patterns in program behavior. They track individual branches and correlations between them. A global history register records recent branch outcomes, indexing into pattern tables that predict future behavior. Some predictors track paths — sequences of branches — to capture control flow patterns. The predictor's state is shared across privilege levels and between different programs, creating a cross-domain communication channel.

Spectre variant 1 exploits conditional branches. Variant 2 targets indirect branches — jumps to addresses computed at runtime, common in object-oriented code and function pointers. The hardware must predict not just taken/not-taken but the actual destination address. The Branch Target Buffer (BTB) caches these predictions, but entries can be poisoned to redirect speculation to attacker-chosen gadgets.

Cache timing provides the physical channel. Processors use multiple cache levels — L1 (closest to CPU, 4 cycles), L2 (12 cycles), L3 (40 cycles), and main memory (200+ cycles). These differences reveal which addresses were accessed. Single-bit leaks, extracted repeatedly, compromise entire keys through differential analysis.

These attacks can extract any data the CPU has access to: passwords stored in memory, cryptographic keys, personal files, browser history, emails, database contents. If the kernel has it in memory, Meltdown can read it. If a program processes sensitive data, Spectre can extract it — even from JavaScript running in a web browser. 

Mitigations constrain speculation at every level. \texttt{LFENCE} instructions create serialization barriers. Kernel page table isolation (KPTI) unmaps kernel memory from user space. Indirect-branch mitigations include retpolines — a Google-developed technique replacing indirect branches with a return-based construct that traps speculation via the return predictor — and hardware IBPB/IBRS/STIBP controls. Some predictors are flushed or partitioned on context switches on newer systems. Each fix degrades the optimization it protects.

Processors achieve high performance through pipelines — 14-19 stages in contemporary designs. Without speculation, a mispredicted branch would flush the pipeline, wasting dozens of cycles. At 4GHz, each wasted cycle represents 250 picoseconds of lost computation. Multiply by billions of branches per second, and performance would drop drastically.

The x86 \texttt{RDTSC}/\texttt{RDTSCP} instructions return a cycle count (cycle-level resolution). Time can be derived given clock frequency; on invariant TSC systems this can approach sub-nanosecond granularity. When restricted, alternatives exist: thread scheduling provides a coarse clock, contention on shared resources amplifies timing differences, and browser JavaScript enables attacks through SharedArrayBuffer spin loops or WebAssembly instruction counting.

After Spectre and Meltdown, each processor optimization became a potential side channel. Vector units, return predictors, schedulers, virtualization boundaries revealed new attack surfaces.

Later attacks exploited other processor features. Downfall (2023) targets Intel's AVX gather instructions — when speculatively gathering data, these vector operations transiently load values from unauthorized memory regions. The values leave cache footprints after rollback, allowing extraction of cryptographic keys by timing which vector elements were accessed. Intel processors from 6th through 11th generation carry this flaw.

Retbleed (2022) demonstrated that even retpolines fail. Return instructions — used in every function call — use their own prediction mechanism. By poisoning the return stack buffer, attackers force speculative execution of arbitrary gadgets, bypassing the carefully constructed retpoline defenses.

Inception (2023) showed AMD processors aren't immune — it creates "phantom speculation" by nesting mispredictions within mispredictions. GhostRace (2024) weaponized something previously thought safe: synchronization primitives. Race conditions during speculative execution leak data even from properly synchronized code.

A fully-mitigated system may run 30\% slower than its vulnerable predecessor. Some workloads see greater degradation — databases that rely heavily on indirect calls, JIT compilers that generate dynamic code, virtualized environments with frequent context switches. Mitigations cost years of Moore's Law gains.


\inlineimage{0.45}{18_SpeculativeExecutionAttacks/Oracle.png}{“Don’t quote me, but the oracle at Delphi told me she’s using ChatGPT.”}