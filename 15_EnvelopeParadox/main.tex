You are presented with two identical envelopes — you are told that one envelope contains twice the money as the other. No other information is given. You select one envelope at random and open it, revealing \$100. At this point, you are given the opportunity to switch.

Consider the reasoning that leads to paradox. The envelope you opened contains \$100, which must be either the smaller amount or the larger. If \$100 is the smaller amount, the other envelope contains \$200. If \$100 is the larger amount, the other envelope contains \$50. Since these two cases seem equally likely, the expected value from switching appears to be:
\[
\text{Expected gain} = 0.5 \cdot (+100) + 0.5 \cdot (-50) = +25.
\]
This suggests a \$25 gain from switching. The same calculation applies regardless of the amount observed, whether \$10, \$100, or \$1000. You should apparently switch every time. But this logic also tells you to switch back again after switching, producing an endless preference loop. The contradiction is that each envelope appears preferable to the other.

Why does this reasoning feel compelling? The calculation follows expected value logic. The probabilities seem reasonable. Without additional information, why shouldn't the observed amount be equally likely to be the smaller or larger? The arithmetic is correct. Yet the conclusion violates intuitions about symmetric problems. The puzzle demands a definitive answer while generating contradictory recommendations.

The error lies in how the observed amount $x$ is interpreted across different terms of the expectation. In one term, $x$ represents the smaller amount; in the other, it represents the larger amount. This reference creates incompatible baselines for comparison.

To make the model coherent, let \( x \) denote the smaller of the two amounts. Then the envelopes contain \( x \) and \( 2x \), and each is equally likely to be selected. If you hold \( x \), switching yields \( +x \); if you hold \( 2x \), switching yields \( -x \). The outcomes cancel:
\[
\text{Average change} = 0.5 \cdot (+x) + 0.5 \cdot (-x) = 0.
\]
No advantage arises. The paradox dissolves because the original argument uses expectation without a consistent model.

This becomes clearer in a bounded setup. Suppose the smaller amount is chosen uniformly from \( \{2^0, 2^1, \dots, 2^{999}\} \). For most observed amounts \( A \), switching seems to yield a gain of \( +0.25A \) since \( A \) could be either the smaller or larger envelope value. However, this ignores boundary cases: if \( A = 2^0 \), switching cannot halve it; if \( A = 2^{999} \), switching cannot double it. These rare but extreme boundary effects precisely cancel the average gain across interior values, returning the total expectation to zero.

In the limit as the model becomes unbounded, for example, when \( x \) is drawn from \( \{\dots, 2^{-2}, 2^{-1}, 2^0, 2^1, \dots\} \), the problem reappears. For any observed amount, switching appears to yield a gain of \( +0.25A \). But this assumes all values are equally probable, which is not possible over an infinite set.

A uniform distribution over an infinite number of values cannot exist — there is no way to assign equal, nonzero probability to infinitely many outcomes and still have the total probability equal to one. Any attempt results in an \emph{improper prior}: a function that resembles a distribution but cannot be normalized.

To reason coherently in such a context, one must use a \emph{probability measure}: a rule that assigns consistent, additive weights to sets of values and sums to one. A measure is \emph{proper} if it satisfies this condition. If it diverges or is undefined, expectations may not exist. Even if each outcome is finite, the global average may be infinite or ill-defined. In that case, expectation ceases to be a meaningful decision tool.

One setup does yield a switching advantage. Fix a value \( a \) and flip a coin: if heads, prepare envelopes with \( a \) and \( 2a \); if tails, use \( a \) and \( a/2 \). Hand the envelope containing \( a \) to the player. Switching yields either \( +a \) or \( -0.5a \) with equal probability, giving an expected gain of \( +0.25a \). Here, switching is optimal because the model is asymmetric and expectation is applied with explicit conditioning.

The switching advantage depends entirely on the unknown prior distribution over envelope pairs. If smaller amounts are more probable, observing \$100 suggests you likely hold the larger envelope. If larger amounts are more probable, the reverse holds. Without knowing this distribution, rational choice becomes impossible.

\textbf{Bertrand's paradox} (1889) poses the question: what is the probability that a random chord of a circle is longer than the side of an inscribed equilateral triangle? The answer depends on what "random" means. Select two random points on the circumference and connect them: the probability is $1/3$. Select a random radius and place the chord perpendicular to it at a random distance from the center: the probability is $1/2$. Select a random interior point as the chord's midpoint: the probability is $1/4$. Each method seems reasonable, yet they yield different results. "Random chord" is undefined without specifying the selection procedure.

Similarly, should you treat envelope pairs $(50, 100)$ and $(100, 200)$ as equally likely? Or should you treat the amounts \$50, \$100, \$200 as equally likely? Each choice determines a different prior over the smaller value $x$. The first approach makes pairs equally likely; the second makes values equally likely, implying smaller values are more probable than larger ones when considering pairs. Without specifying the generation mechanism, "random envelope" has no unique meaning, and the "principle of indifference" — treating outcomes as equally likely in the absence of information — produces contradictions.

The Bayesian approach requires a prior distribution over envelope pairs. Without knowing the generation mechanism, no prior can be justified. Even given a distribution, improper priors (such as uniform over all positive reals) produce undefined probabilities, and heavy-tailed distributions yield infinite expected values. In symmetric setups, observing one amount provides zero information about which envelope contains more. Over repeated trials with any proper distribution, switching gains nothing on average.

\begin{commentary}[Reasoning with and around Paradoxes]
Probability paradoxes often arise from extending otherwise reliable tools, such as symmetry, expectation, or conditional likelihood, beyond the domains where they are mathematically coherent. Once the generative assumptions are clarified, the contradiction typically disappears.

Analytical resolution involves selecting a valid prior over the smaller amount and computing the conditional expectation given the observed value. But intuition often fails before analysis begins. The paradox feels persuasive because it aligns with a mental shortcut: the imagined gain from doubling exceeds the loss from halving. Moreover, simulations over bounded ranges frequently reproduce this 25\% average gain in the interior of the distribution, while obscuring the boundary corrections that neutralize the effect.

A complementary tool is empirical. By simulating the game with a finite model, such as drawing $x$ from a list of powers of two, one can directly compare switching and staying strategies:
\newpage
\begin{verbatim}
import random

base = [2**i for i in range(30)]  # bounded distribution

def switch_strategy():
    x = random.choice(base)
    amount = random.choice([x, 2*x])
    # Faulty logic: assumes unbounded doubling/halving
    return 2 * amount if amount == x else amount / 2

def no_switch_strategy():
    x = random.choice(base)
    return random.choice([x, 2*x])

# Run simulation (n = 10^6)
switch_avg = sum(switch_strategy() for _ in range(10**6)) / 10**6
stay_avg = sum(no_switch_strategy() for _ in range(10**6)) / 10**6
\end{verbatim}

The switching strategy appears advantageous, but only because it violates the constraint that envelope pairs must come from the predefined base set. Switching from \( 2^{29} \) yields \( 2^{30} \), even though that value was not part of the original distribution.

To resolve the paradox, add proper boundary checking:

\begin{verbatim}
# Correct switching with bounds
if amount == x:  # smaller value
    new = 2 * amount
    return new if new in base else amount
else:  # larger value  
    new = amount // 2
    return new if new in base else amount
\end{verbatim}

With this correction, the switching advantage disappears entirely. The simulation confirms the formal result: in a symmetric, finite model, switching yields no net gain once edge conditions are treated correctly.

Simulation is not a substitute for proof, yet it helps clarify where the paradox gains its force.

\end{commentary}