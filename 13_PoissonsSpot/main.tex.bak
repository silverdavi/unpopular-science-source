In the dominant optical theory of the 18th century, light was conceived as a stream of discrete particles governed by Newtonian mechanics. Isaac Newton's \textit{Opticks} (1704) formalized this corpuscular model, arguing that light rays consist of minute corpuscles emitted from luminous bodies and traveling in straight lines. Reflection was explained as an elastic rebound from surfaces, while refraction was attributed to short-range attractive forces exerted by denser media, accelerating the particles and bending their trajectories toward the normal.

To support the theory, Newton conducted a series of controlled experiments using prisms, lenses, and narrow apertures. He systematically investigated the behavior of light under dispersion, interference, and filtering conditions, recording the colors and intensities projected onto screens. In his most influential experiment, he demonstrated that white light could be decomposed into component colors using a glass prism and then recombined into white light using a second prism positioned in reverse.

The corpuscular model accounted for key optical observations such as rectilinear propagation, sharp shadows, and well-defined reflections from mirrors. It also offered coherence: by avoiding dependence on any physical transmission medium, the theory preserved the principle of action at a distance and aligned with Newton's general program of universal mechanics.

A competing model had been introduced by Christiaan Huygens in 1678, proposing that light propagated as a continuous wave. In this formulation, each point on a wavefront was treated as a source of secondary spherical disturbances, which spread outward in all directions. The superposition of these wavelets formed a new wavefront — defined as the envelope tangent to all secondary spheres — a geometric construction now known as the Huygens principle. This approach permitted derivation of the laws of reflection and refraction using geometric reasoning and offered an alternative to the ballistic model without invoking interfacial forces.

Huygens' wave theory reproduced Snell's law by modeling light as a wavefront that changes orientation when passing into a medium where wave speed decreases. This accounted for refraction by assigning slower propagation to denser materials, a reversal of the corpuscular model's velocity assumption, later confirmed experimentally. The wave approach also gave qualitative explanations for diffraction and interference, though these effects had not yet been studied in systematic detail.

The theory required a universal propagation medium, the luminiferous ether, assumed to carry transverse vibrations through empty space. This posed internal difficulties: the ether needed to be rigid enough for high wave speeds but remained undetectable in mechanical or optical measurements. The model also offered no obvious account for sharply defined edges or specular reflection, which limited its compatibility with geometric optical effects.

By the early 1800s, the corpuscular theory retained institutional dominance in British science. Newton's \textit{Opticks}, first published in 1704 and reissued in expanded editions through the mid-18th century, remained the authoritative source on optical behavior. Its treatments of reflection, refraction, and chromatic dispersion were widely accepted as definitive, and its success in reproducing geometric light paths reinforced its credibility within Newtonian mechanics.

On the continent, especially within the French Academy of Sciences, Huygens' wave theory received more sustained attention, though it remained a minority position. Even as late as 1815, standard French accounts described diffraction as a peripheral anomaly rather than a core optical effect. Classical phenomena, mirror reflection, Snell's law, and prism-induced color separation, were consistent with both frameworks. In the absence of distinct, falsifiable predictions, theoretical preferences were often shaped by broader methodological and philosophical alignments.

In 1801, Thomas Young presented experiments to the Royal Society showing that monochromatic light passing through two narrow, parallel slits produced a regular pattern of alternating bright and dark fringes on a distant screen. The results depended on slit geometry and color, and the visibility of the fringes required careful alignment. The interference pattern was stable, reproducible, and inconsistent with the behavior of independent particles traveling in straight lines.

Young explained the pattern using the principle of superposition: coherent wavefronts emanating from the two slits combined with relative phase shifts that depended on path difference. At some locations, the waves interfered constructively; at others, destructively. While this interpretation was met with skepticism in Britain, where Newtonian mechanics held institutional authority, it found more interest in France. There, analytic approaches to physical phenomena were gaining prominence, and interference was increasingly viewed as a direct signature of wave behavior.

In the 19th century, the French Academy of Sciences organized public prize competitions to address unresolved scientific questions. These Grand Prix offered formal recognition and were intended to establish clarity on foundational issues. Notable winners of contemporary Grand Prix included Joseph Fourier (1810, for heat conduction), Jean-Baptiste Biot (1812, for electricity and magnetism), Sophie Germain (1816, for the theory of elastic surfaces — the first woman to win a Grand Prix from the Academy), and Siméon Denis Poisson (1819, for mechanics), establishing the prizes as a prestigious venue for scientific advancement.

This same tradition led to the 1818 announcement of a prize for the best theoretical account of diffraction. At the time, no existing model could give a complete explanation of the observed phenomena. The corpuscular theory remained standard in Britain, while some continental physicists were exploring wave-based descriptions grounded in interference.

Only two entries were received — the first, now lost and submitted anonymously, was rejected outright. The committee noted its neglect of known experimental results, its unfamiliarity with prior work by Young and Fresnel, and its numerous conceptual and computational errors. The second submission, authored by Augustin-Jean Fresnel, presented a detailed mathematical treatment of diffraction using the wave hypothesis. Fresnel extended Huygens' geometric principle by modeling light as a scalar disturbance with definable amplitude and phase. He introduced an integral formulation in which secondary wavelets emanating from every point on a wavefront interfered according to phase delay, yielding precise intensity predictions behind apertures and opaque obstacles. These predictions were derived entirely from geometry and propagation delay, without recourse to forces or ballistic mechanisms.

The response from the judging committee exposed a divide. Siméon Denis Poisson, an influential Newtonian, examined Fresnel's equations with the aim of identifying contradictions. He derived what he considered a decisive counterexample: were the wave theory valid, then a circular opaque disk should produce a bright spot at the center of its geometric shadow. From the perspective of corpuscular optics, such a prediction was absurd. That region received no direct rays and should remain dark. Poisson concluded that this result, clearly at odds with particle reasoning and common sense, invalidated Fresnel's model as a whole.

Dominique Arago, also on the committee but less ideologically aligned with Newtonian mechanics, recognized that Poisson's objection could be tested directly. He constructed an experimental apparatus using a monochromatic point source, a small circular obstruction, and a screen positioned along a collimated beam path. Under proper alignment, a narrow bright point consistently appeared at the center of the shadow, exactly as predicted by Fresnel's analysis. The result was repeatable, insensitive to minor perturbations — and could not be reconciled with any particle-based mechanism. It provided direct empirical confirmation that phase-based wave interference governed the observed pattern. The spot's appearance is consistent with Babinet's principle: an opaque disk and an aperture of equal size produce identical diffraction patterns, so the constructive interference at the disk's center mirrors the bright center of a circular aperture.

The confirmation of the Arago spot resolved a challenge to the wave theory. It reinforced the rising standard for evaluating physical theories: the ability to produce precise, testable predictions from mathematical formulations applied to specific conditions.

The corpuscular theory could not reproduce the observed intensity maximum. No assumption about particle trajectories, angular spread, or probabilistic scattering could account for constructive illumination at the shadow's center. The appearance of the Arago spot showed that physical models must be judged by whether their equations generate correct spatial distributions, not by whether their assumptions align with intuition. Predictive precision replaced plausibility as the standard for theoretical acceptance.

\begin{figure}[h]
\centering
\begin{tikzpicture}[scale=0.65, thick]

% Styles
\tikzstyle{wavefront}=[gray, dashed]
\tikzstyle{lightpath}=[->, >=latex, blue!60!black]
\tikzstyle{obstacle}=[line width=1.2pt]
\tikzstyle{screen}=[line width=1pt, gray!60!black]
\tikzstyle{spot}=[fill=red!60, draw=black]

% Point source
\filldraw[black] (-4,0) circle (0.06) node[above left] {Source};

% Wavefronts (concentric arcs)
\foreach \r in {0.7,1.4,2.1,2.8}
    \draw[wavefront] (-4,0) ++(\r, \r) arc[start angle=90, end angle=-90, radius=\r];

% Opaque disk (cross-section as vertical bar)
\draw[obstacle] (0,-1.2) -- (0,1.2);
\node[above] at (0,1.2) {Opaque Disk};

% Light paths diffracted around disk to spot
\draw[lightpath] (-4,0) -- (0,1.2);
\draw[lightpath] (-4,0) -- (0,-1.2);
\draw[lightpath] (0,1.2) .. controls (1.5,0.8) .. (3,0);
\draw[lightpath] (0,-1.2) .. controls (1.5,-0.8) .. (3,0);

% Screen
\draw[screen] (3,-1.6) -- (3,1.6);
\node[above] at (3,1.6) {Screen};

% Arago spot
\filldraw[spot] (3,0) circle (0.07);
\node[right] at (3.1,0) {Arago Spot};

% Shadow label
\draw[gray!60, <->] (0,-1.4) -- (3,-1.4);
\node[gray!60] at (1.5,-1.65) {Geometric shadow region};

\end{tikzpicture}
\caption{Diffraction around a circular obstacle produces constructive interference at the center of the geometric shadow: the Arago spot.}
\end{figure}

This standard was challenged again in the early 20th century, when new experiments revealed optical behavior that neither wave theory nor particle theory could explain in full. The concept of duality arose in response to this fragmentation.

Diffraction, interference, and polarization aligned with wave theory, particularly as formulated by Maxwell's equations, which described light as a transverse electromagnetic wave propagating through space. In contrast, the photoelectric effect (emission of electrons from a metal when illuminated) and Compton scattering (inelastic scattering of photons by electrons) could not be explained by continuous fields. Each domain appeared to demand a separate formalism: wave optics for propagation, and quantum mechanics for emission and absorption.

This division extended into mathematical treatment. Wave behavior was modeled using Maxwell's classical field equations, which predicted interference patterns and polarization with high accuracy. Particle behavior was captured by early quantum mechanics, where photons were treated as quantized packets of energy and momentum. As a result, physicists adopted a pragmatic view: light exhibits wave-like properties in some experiments and particle-like behavior in others. The term "duality" was used as a placeholder for the absence of a single consistent description. Though heuristically useful, this terminology preserved the conceptual split rather than resolving it.

Quantum electrodynamics, the modern quantum field theory of light, treats light as a quantized electromagnetic field. Photons are discrete energy-momentum packets, arising from specific field modes. They are not classical particles with trajectories, nor simple waves in a medium. The field spans spacetime and interacts with detectors through localized energy exchanges. Its behavior follows rules that describe propagation and interaction.

Photon states are described using quantum field theory, built from the quantized modes of the electromagnetic field. Each state carries momentum, polarization, and frequency. Measurements correspond to specific detector responses. The theory provides exact rules for calculating detection probabilities, scattering processes, and energy transfers without classical analogies.

The Arago spot results from coherent superposition of field amplitudes from different spatial regions. Each amplitude picks up a phase based on its path and boundary conditions. The total intensity comes from summing these complex amplitudes and taking their absolute value squared. This produces the observed pattern on screen, including a central bright point where waves interfere constructively.

When light intensity drops to single photons, each detection event remains a point. Over time, their distribution recreates the interference pattern. This confirms that probability amplitudes maintain phase relationships even in the quantum regime. The spot depends not on averaging many photons but on the field's linear behavior and phase relationships between paths.

What appears as wave-particle duality emerges from viewing the quantum field through different experimental lenses. The field's equations produce patterns mathematically similar to classical interference when examined through intensity measurements, yet yield particle-like detection events when observed through photon counters. Epistemologically, there is no duality — only a well-defined quantum field with observable operators.

This rejection of the notion of light's "dual-nature" is important. In economics, Okun's Law relates changes in unemployment to deviations of GDP (gross domestic product) growth from its potential, taking a form mathematically similar to Hooke's Law for springs with a proportional "restoring" effect. Yet this does not mean unemployment \textit{is} a spring. In the same way, resemblance of quantum behavior to either waves or particles reflects the equations and measurements, not the essence of what light actually is.