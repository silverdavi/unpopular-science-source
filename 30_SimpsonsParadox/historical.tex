\begin{historical}
Early statisticians, including G. Udny Yule (1903) and Karl Pearson, documented reversals that arise when aggregated data obscure subgroup relationships. In several early case studies, trends within groups differed from the pooled trend, foreshadowing the formal statement later articulated by Simpson.

Edward H. Simpson published a four-page paper in 1951 in the Journal of the Royal Statistical Society. He proved that for any proportions $a/b < c/d$ and $e/f < g/h$, it remains algebraically possible that $(a+e)/(b+f) > (c+g)/(d+h)$. Simpson's formulation established the general conditions under which combining data groups reverses their individual trends.

The paradox gained widespread attention through the 1973 Berkeley graduate admissions analysis by P.J. Bickel, E.A. Hammel, and J.W. O'Connell. Raw data showed women had a 35\% acceptance rate compared to 44\% for men. Department-specific analysis revealed no discrimination — women had equal or higher acceptance rates in four of six departments. Women applied more frequently to highly competitive departments with much lower acceptance rates, while men applied more to less selective departments. The differing application patterns created the aggregate disparity.

Simpson's result appears in medical trials when treatments are assigned based on patient severity, in election analysis when votes are aggregated by district, and in machine learning when training sets are partitioned. Colin R. Blyth coined the term “Simpson's paradox” in 1972, though Udny Yule had described similar reversals in 1903. The phenomenon is sometimes called the Yule-Simpson effect.

The same mathematics that creates accidental reversals enables deliberate manipulation through gerrymandering. Elbridge Gerry signed a redistricting bill in Massachusetts in 1812 that created a salamander-shaped district to concentrate opposition voters, giving the practice its name. The underlying strategy of manipulating representation, however, has deeper roots in British “rotten boroughs”, which were used to control elections by packing (concentrating them in a few districts) or cracking (splitting them across many) voters.

With the rise of computer-assisted mapping after the 1990 census, gerrymandering became a science, allowing partisan mapmakers to secure durable advantages in evenly divided electorates. After a mid-decade redistricting in Texas in 2003 reshaped the congressional balance of power, courts increasingly employed mathematical diagnostics — such as the efficiency gap, mean-median difference, and ensemble simulation tests — to determine when district boundaries purposefully waste opposition votes through packing or cracking. 
\end{historical}
